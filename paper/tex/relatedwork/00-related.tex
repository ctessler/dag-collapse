\section{Related Work}\label{sec:related}
Real-time scheduling for single thread tasks models without any cache consideration was explored in~\cite{Liu:2000,Hennessey:2011 }. Worst-case execution time computation with cache benefit stemming from instruction cache reuse for sequential tasks was studied for direct mapped caches in~\cite{Arnold:1994, Mueller:1995,Mueller:2000} and set-associative caches in~\cite{Li:1996}. Scheduler overheads for fixed priority preemptive schedulers and context switch costs were studied in~\cite{burns:1993, katcher:1993}. Cache overheads during preemptions or CRPD (cache related preemption delay) was studied from the perspective of the preempted task (or only ECB's) in~\cite{Tomiyama:2000, tan:2007}, preempting task (or only UCB's) in~\cite{Lee:1998, altmeyer:2011, negi:2003} and a combination of preempted and preempting task (or ECB-UCB) in~\cite{staschulat:2005}. A multi-set approach with a tighter result on cache  was proposed in~\cite{altmeyer:2012}. These results were extended to EDF schedulers~\cite{ju:2007, lunniss:2014a, lunniss:2013} and hierarchical scheduling in~\cite{lunniss:2016, lunniss:2014b}. 
A memory-centric scheduling for predictable execution model was proposed in~\cite{Bak:2012, Pellizzoni:2011} and was later extended to mixed criticality systems in~\cite{Ward:2013}. Persistence cache blocks~\cite{Rashid:2016} takes a different perspective by looking into re-usable cache blocks that are present in the cache after the first job release. Cache related preemption overhead considering ECB's, UCB's, and persistence cache block was studied in~\cite{Rashid:2017}. 
These methods only consider a single tread execution model.  A  feasibility analysis for the fork-join model was studied in~\cite{Sun:2016}.   Concurrent program analysis studied in~\cite{Mittermayr:2012} was extended to consider variable configurations such as shared multi-level caches in~\cite{Li:2009}. CRPD for multi-level inclusive~\cite{zhang2016cache} and non-inclusive caches~\cite{chattopadhyay2014cache} were studied recently. These works consider a negative impact of caches on the worst-case execution time and schedulability analysis.


We are aware of two techniques that take a positive perspective on caches. Calandrino~\cite{Calandrino:2009} limits the cache spread of threads (called subtasks) for multi-threaded tasks. BUNDLE~\cite{tessler:2016} and BUNDLEP~\cite{tessler:2018} introduce inter-thread c,ache benefits for mutli-threading task models. However, they are only applicable for a sequential task, i.e., all threads are executing on the same core. On the contrary, in this paper, we focus on parallel execution model, where threads can execute on simultaneous cores.

Recently, federated~\cite{li2014federated, baruah2015federated, ueter2018reservation} and global schedulers~\cite{saifullah2013multi, lakshmanan2010scheduling, baruah2015global} for parallel real-time tasks were proposed. Analysis of the parallel real-time schedulers was proposed in~\cite{li2013, li2014analysis, bonifaci2013feasibility, andersson2012analyzing, baruah2014improved, serrano2016response}. The design and analysis of parallel real-time task schedulers were extended to a consider a more general conditional parallel task model with conditional branches between nodes in~\cite{melani2015response, baruah2015federated, sun2018capacity}. Energy-aware parallel real-time task scheduler was proposed in~\cite{guo2017energy}. Recently, blocking analysis for spinlocks in parallel real-time tasks was studied in~\cite{dinh2018blocking}. However, these methods do not consider the impact of cache on the schedulers. To the best of our knowledge, this is the first work that considers inter-thread cache benefit for parallel real-time tasks.
 











